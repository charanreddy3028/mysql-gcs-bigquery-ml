# ğŸš€ End-to-End Data Pipeline: MySQL â†’ GCS â†’ BigQuery â†’ Local Analytics

[![Airflow DAGs](https://img.shields.io/badge/Airflow-DAGs-blue)](https://airflow.apache.org/)  
[![BigQuery](https://img.shields.io/badge/BigQuery-GCP-yellow)](https://cloud.google.com/bigquery)  
[![GCS](https://img.shields.io/badge/Storage-GCS-blueviolet)](https://cloud.google.com/storage)  
[![Python](https://img.shields.io/badge/Python-Local--ML-green)](https://www.python.org/)  

---

## ğŸ“Œ Project Overview

This project implements a scalable, automated data pipeline that extracts data from MySQL, transforms it through three logical layers (**Bronze â†’ Silver â†’ Gold**), and integrates with **Google Cloud Storage** and **BigQuery**. It enables both cloud-based querying and local analytics, including daily machine learning predictions.

---

## ğŸ” Data Flow Architecture

       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚  MySQL   â”‚
       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
            â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚   Bronze Layer     â”‚ â†’ Raw data from MySQL stored in GCS
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚   Silver Layer     â”‚ â†’ Cleaned/validated data stored in GCS
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚   Gold Layer       â”‚ â†’ Final transformed data stored in GCS
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚    BigQuery        â”‚ â† Only Gold Layer is loaded here
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚   Local System     â”‚ â†’ Advanced analytics & ML training
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚   Predictions      â”‚ â†’ Sent back to BigQuery
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    [ Orchestrated Daily via Airflow DAGs ]


---

## ğŸ› ï¸ Tech Stack

| Layer           | Tool/Service             |
|-----------------|--------------------------|
| Data Source     | MySQL                    |
| Storage         | Google Cloud Storage     |
| Data Warehouse  | Google BigQuery          |
| Workflow Engine | Apache Airflow           |
| ML/Analytics    | Python (Local)           |

---

## ğŸ“ˆ Key Features

- âœ… Modular architecture using Bronze, Silver, and Gold layers  
- â˜ï¸ Scalable cloud storage and compute using GCS & BigQuery  
- ğŸ” Automated ETL and model training using Airflow DAGs  
- ğŸ§  Local system used for ML pipelines & advanced analytics  
- ğŸ“¤ Daily predictions pushed back to BigQuery

---

## ğŸš€ Getting Started

### Prerequisites

- Google Cloud Project (GCS & BigQuery enabled)  
- Apache Airflow setup (locally or via Cloud Composer)  
- Python 3.8+ environment for local ML processing  
- MySQL access credentials  

### Setup Steps

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/your-repo.git
   cd your-repo
Configure MySQL and GCP credentials
Add your credentials in the .env or config.py as needed.

Set up DAGs in Airflow
Place DAG scripts in your Airflow /dags folder.
Trigger or schedule DAGs.

Run local analytics

bash
Copy
Edit
python analytics/predict.py
View results
See results in BigQuery or Looker Studio.

ğŸ“… Automation
All pipeline steps are orchestrated via Airflow DAGs, which:

Extract data from MySQL daily

Stage and transform data into GCS

Load Gold Layer to BigQuery

Trigger local scripts for ML training & predictions

